{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155cdd40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fdc4e531",
   "metadata": {},
   "source": [
    "Build Your First RAG System From Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41252aa1",
   "metadata": {},
   "source": [
    "Forget expensive APIs and proprietary databases. We’re doing this with the tools that real engineers use to build powerful, scalable systems. Here are the tools we will be using:\n",
    "\n",
    "1. transformers (Hugging Face): To get our powerful, free LLM.\n",
    "\n",
    "2. sentence-transformers: The easiest way to get a top-tier embedding model.\n",
    "\n",
    "3. faiss-cpu: Facebook AI’s blazing-fast, free vector search library. It’s our vector store.\n",
    "\n",
    "4. langchain: We’ll only use its text splitter, which is a smart shortcut that saves us hours of regex pain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bc4387",
   "metadata": {},
   "source": [
    "Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a101c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 0 chunks:\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Load our document\n",
    "with open(\"my_knowledge.txt\") as f:\n",
    "    knowledge_text = f.read()\n",
    "\n",
    "# 1. Initialize the Text Splitter\n",
    "# This splitter is smart. It tries to split on paragraphs (\"\\n\\n\"),\n",
    "# then newlines (\"\\n\"), then spaces (\" \"), to keep semantically\n",
    "# related text together as much as possible.\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=150,  # Max size of a chunk\n",
    "    chunk_overlap=20, # Overlap to maintain context between chunks\n",
    "    length_function=len\n",
    ")\n",
    "\n",
    "# 2. Create the chunks\n",
    "chunks = text_splitter.split_text(knowledge_text)\n",
    "\n",
    "print(f\"We have {len(chunks)} chunks:\")\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"--- Chunk {i+1} ---\\n{chunk}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf8627d",
   "metadata": {},
   "source": [
    "Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea91c5aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text length: 0\n"
     ]
    }
   ],
   "source": [
    "with open(\"my_knowledge.txt\", encoding=\"utf-8\") as f:\n",
    "    data = f.read()\n",
    "\n",
    "print(\"Text length:\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02425c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Folder: c:\\Coding\\Desktop\\Projects\\projects\\RAG From Scratch\n",
      "Files in folder: ['my_knowledge.txt', 'rag.ipynb']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(\"Current Folder:\", os.getcwd())\n",
    "print(\"Files in folder:\", os.listdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92b14fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File size: 0 bytes\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "file_path = \"my_knowledge.txt\"\n",
    "\n",
    "print(\"File size:\", os.path.getsize(file_path), \"bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "656aef03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute Path: c:\\Coding\\Desktop\\Projects\\projects\\RAG From Scratch\\my_knowledge.txt\n",
      "Exists: True\n",
      "File Size: 0 bytes\n",
      "Length: 0\n",
      "Raw Content: ''\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "file_path = os.path.abspath(\"my_knowledge.txt\")\n",
    "\n",
    "print(\"Absolute Path:\", file_path)\n",
    "print(\"Exists:\", os.path.exists(file_path))\n",
    "print(\"File Size:\", os.path.getsize(file_path), \"bytes\")\n",
    "\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    content = f.read()\n",
    "\n",
    "print(\"Length:\", len(content))\n",
    "print(\"Raw Content:\", repr(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87970b21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
