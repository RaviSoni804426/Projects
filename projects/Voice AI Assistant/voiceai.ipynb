{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aeff418a",
   "metadata": {},
   "source": [
    "How a Voice AI Assistant Works in Real-time?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b66f4f",
   "metadata": {},
   "source": [
    "Before we write the code, let‚Äôs understand what we are building. An AI voice assistant is essentially a loop of three distinct biological functions replicated by code:\n",
    "\n",
    "1.The Ears (Speech-to-Text): We capture audio vibrations and translate them into text.\n",
    "\n",
    "2. The Brain (LLM Inference): We send that text to a Large Language Model (Ollama/Llama 3) to generate a smart response.\n",
    "\n",
    "3. The Mouth (Text-to-Speech): We convert the AI‚Äôs text response back into audio so we can hear it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a00258",
   "metadata": {},
   "source": [
    "1Ô∏è‚É£ IMPORT SECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ca90f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== IMPORTS =====\n",
    "\n",
    "import speech_recognition as sr\n",
    "import pyttsx3\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62748b4c",
   "metadata": {},
   "source": [
    "2Ô∏è‚É£ EARS (Speech to Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88d69b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== EARS (Listening System) =====\n",
    "\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "def listen():\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"üé§ Listening...\")\n",
    "        recognizer.adjust_for_ambient_noise(source, duration=0.5)\n",
    "        audio = recognizer.listen(source)\n",
    "\n",
    "        try:\n",
    "            text = recognizer.recognize_google(audio)\n",
    "            print(\"üó£ You said:\", text)\n",
    "            return text\n",
    "        except:\n",
    "            print(\"‚ö†Ô∏è Could not understand.\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52856257",
   "metadata": {},
   "source": [
    "3Ô∏è‚É£ BRAIN (Small Local LLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13dca0e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eed907a5db774b128cf67d7274fa1a41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/190 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tied weights mapping and config for this model specifies to tie shared.weight to lm_head.weight, but both are present in the checkpoints, so we will NOT tie them. You should update the config with `tie_word_embeddings=False` to silence this warning\n"
     ]
    }
   ],
   "source": [
    "# ===== BRAIN (AI Thinking) =====\n",
    "\n",
    "model_name = \"google/flan-t5-small\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "model.to(\"cpu\")\n",
    "\n",
    "def think(user_input):\n",
    "    prompt = f\"Answer clearly and concisely:\\n{user_input}\"\n",
    "\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=100,\n",
    "        do_sample=False\n",
    "    )\n",
    "\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5f97e4",
   "metadata": {},
   "source": [
    "4Ô∏è‚É£ MOUTH (Text to Speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5c931d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== MOUTH (Windows Safe Version) =====\n",
    "\n",
    "from gtts import gTTS\n",
    "import os\n",
    "import time\n",
    "\n",
    "def speak(text):\n",
    "    print(\"ü§ñ AI:\", text)\n",
    "    \n",
    "    filename = \"response.mp3\"\n",
    "    \n",
    "    # Convert text to speech\n",
    "    tts = gTTS(text=text, lang=\"en\")\n",
    "    tts.save(filename)\n",
    "    \n",
    "    # Play using Windows default player\n",
    "    os.system(f\"start {filename}\")\n",
    "    \n",
    "    # Optional: wait and cleanup\n",
    "    time.sleep(5)\n",
    "    if os.path.exists(filename):\n",
    "        os.remove(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586b078f",
   "metadata": {},
   "source": [
    "5Ô∏è‚É£ MAIN (Control Center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "718f989d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Voice AI Assistant Started\n",
      "Say 'stop' to exit.\n",
      "\n",
      "üé§ Listening...\n",
      "üó£ You said: hello hello hello hello hello hello hello hello hello hello hello\n",
      "ü§ñ AI: hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello hello\n",
      "üé§ Listening...\n",
      "‚ö†Ô∏è Could not understand.\n",
      "üé§ Listening...\n",
      "‚ö†Ô∏è Could not understand.\n",
      "üé§ Listening...\n",
      "üó£ You said: stop stop\n",
      "ü§ñ AI: Goodbye Ravi. Have a great day!\n"
     ]
    }
   ],
   "source": [
    "# ===== MAIN LOOP =====\n",
    "\n",
    "print(\"ü§ñ Voice AI Assistant Started\")\n",
    "print(\"Say 'stop' to exit.\\n\")\n",
    "\n",
    "while True:\n",
    "    user_input = listen()\n",
    "\n",
    "    if user_input is None:\n",
    "        continue\n",
    "\n",
    "    if \"stop\" in user_input.lower():\n",
    "        speak(\"Goodbye Ravi. Have a great day!\")\n",
    "        break\n",
    "\n",
    "    response = think(user_input)\n",
    "    speak(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
