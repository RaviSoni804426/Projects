{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33bd450b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in C:\\Coding\\Desktop\\Projects\\venv\\Lib\\site-packages (2.32.5)\n",
      "Requirement already satisfied: beautifulsoup4 in C:\\Coding\\Desktop\\Projects\\venv\\Lib\\site-packages (4.14.3)\n",
      "Requirement already satisfied: pandas in C:\\Coding\\Desktop\\Projects\\venv\\Lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in C:\\Coding\\Desktop\\Projects\\venv\\Lib\\site-packages (from requests) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in C:\\Coding\\Desktop\\Projects\\venv\\Lib\\site-packages (from requests) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in C:\\Coding\\Desktop\\Projects\\venv\\Lib\\site-packages (from requests) (2.6.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in C:\\Coding\\Desktop\\Projects\\venv\\Lib\\site-packages (from requests) (2026.1.4)\n",
      "Requirement already satisfied: soupsieve>=1.6.1 in C:\\Coding\\Desktop\\Projects\\venv\\Lib\\site-packages (from beautifulsoup4) (2.8.3)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in C:\\Coding\\Desktop\\Projects\\venv\\Lib\\site-packages (from beautifulsoup4) (4.15.0)\n",
      "Requirement already satisfied: numpy>=1.23.2 in C:\\Coding\\Desktop\\Projects\\venv\\Lib\\site-packages (from pandas) (2.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in C:\\Coding\\Desktop\\Projects\\venv\\Lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in C:\\Coding\\Desktop\\Projects\\venv\\Lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in C:\\Coding\\Desktop\\Projects\\venv\\Lib\\site-packages (from pandas) (2025.3)\n",
      "Requirement already satisfied: six>=1.5 in C:\\Coding\\Desktop\\Projects\\venv\\Lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests beautifulsoup4 pandas\n",
    "\n",
    "import requests\n",
    "import time\n",
    "import random\n",
    "import json\n",
    "import pandas as pd\n",
    "import urllib.robotparser\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4048419",
   "metadata": {},
   "source": [
    "1. Logging Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94a03b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log(message, level=\"INFO\"):\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print(f\"[{timestamp}] [{level}] {message}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628d5cff",
   "metadata": {},
   "source": [
    "2. Robots.txt Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d10028e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_allowed(url, user_agent=\"CompliantScraperBot\"):\n",
    "    rp = urllib.robotparser.RobotFileParser()\n",
    "    base_url = \"/\".join(url.split(\"/\")[:3])\n",
    "    robots_url = base_url + \"/robots.txt\"\n",
    "\n",
    "    try:\n",
    "        rp.set_url(robots_url)\n",
    "        rp.read()\n",
    "        allowed = rp.can_fetch(user_agent, url)\n",
    "        return allowed\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cccf26c",
   "metadata": {},
   "source": [
    "3. Fetch with Exponential Backoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db0df959",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_with_retry(url, retries=3):\n",
    "    delay = 2\n",
    "    headers = {\"User-Agent\": \"CompliantScraperBot\"}\n",
    "\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            response = requests.get(url, headers=headers, timeout=10)\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                return response\n",
    "\n",
    "            elif response.status_code in [429, 500, 502, 503]:\n",
    "                log(f\"Retry {attempt+1} due to {response.status_code}\")\n",
    "                time.sleep(delay)\n",
    "                delay *= 2\n",
    "\n",
    "        except Exception as e:\n",
    "            log(f\"Error: {str(e)}\", \"ERROR\")\n",
    "            time.sleep(delay)\n",
    "            delay *= 2\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f15156",
   "metadata": {},
   "source": [
    "4. CAPTCHA / Block Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2efbde",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2772da39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_block(text):\n",
    "    keywords = [\"captcha\", \"blocked\", \"access denied\", \"unusual traffic\"]\n",
    "    for word in keywords:\n",
    "        if word in text.lower():\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae4d594",
   "metadata": {},
   "source": [
    "5. HTML Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7c66ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_html(html, url):\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    # Title\n",
    "    title = soup.title.string.strip() if soup.title else None\n",
    "\n",
    "    # H1 (first visible)\n",
    "    h1_tags = soup.find_all(\"h1\")\n",
    "    h1 = h1_tags[0].get_text(strip=True) if h1_tags else None\n",
    "\n",
    "    # Meta Description\n",
    "    meta_tag = soup.find(\"meta\", attrs={\"name\": \"description\"})\n",
    "    meta_description = meta_tag[\"content\"] if meta_tag else None\n",
    "\n",
    "    # Rating from JSON-LD\n",
    "    rating = None\n",
    "    review_count = None\n",
    "\n",
    "    scripts = soup.find_all(\"script\", type=\"application/ld+json\")\n",
    "\n",
    "    for script in scripts:\n",
    "        try:\n",
    "            data = json.loads(script.string)\n",
    "            if isinstance(data, dict) and \"aggregateRating\" in data:\n",
    "                rating = data[\"aggregateRating\"].get(\"ratingValue\")\n",
    "                review_count = data[\"aggregateRating\"].get(\"reviewCount\")\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    # CTA Buttons\n",
    "    ctas = []\n",
    "    for a in soup.find_all(\"a\"):\n",
    "        text = a.get_text(strip=True)\n",
    "        link = a.get(\"href\")\n",
    "        if text and link:\n",
    "            ctas.append({\"text\": text, \"link\": link})\n",
    "\n",
    "    return {\n",
    "        \"url\": url,\n",
    "        \"title\": title,\n",
    "        \"h1\": h1,\n",
    "        \"meta_description\": meta_description,\n",
    "        \"rating\": rating,\n",
    "        \"review_count\": review_count,\n",
    "        \"pricing\": None,\n",
    "        \"ctas\": ctas,\n",
    "        \"status\": \"ok\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20a8525",
   "metadata": {},
   "source": [
    "6. Main Execution Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd22b4e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2026-02-23 23:02:08] [INFO] Processing https://theresanaiforthat.com/\n",
      "[2026-02-23 23:02:15] [ERROR] Blocked detected!\n",
      "[2026-02-23 23:02:15] [INFO] Scraping completed.\n"
     ]
    }
   ],
   "source": [
    "urls = [\"https://theresanaiforthat.com/\"]\n",
    "\n",
    "results = []\n",
    "\n",
    "for url in urls:\n",
    "    log(f\"Processing {url}\")\n",
    "\n",
    "    # Robots check\n",
    "    if not is_allowed(url):\n",
    "        log(\"Skipped due to robots.txt\")\n",
    "        results.append({\"url\": url, \"status\": \"skipped\"})\n",
    "        continue\n",
    "\n",
    "    # Polite delay\n",
    "    time.sleep(random.uniform(2, 5))\n",
    "\n",
    "    # Fetch\n",
    "    response = fetch_with_retry(url)\n",
    "\n",
    "    if not response:\n",
    "        results.append({\"url\": url, \"status\": \"failed\"})\n",
    "        continue\n",
    "\n",
    "    # Block detection\n",
    "    if detect_block(response.text):\n",
    "        log(\"Blocked detected!\", \"ERROR\")\n",
    "        results.append({\"url\": url, \"status\": \"blocked\"})\n",
    "        continue\n",
    "\n",
    "    # Parse\n",
    "    parsed_data = parse_html(response.text, url)\n",
    "    results.append(parsed_data)\n",
    "\n",
    "log(\"Scraping completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03817874",
   "metadata": {},
   "source": [
    "7. Save JSON + CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46bb9075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2026-02-23 23:02:37] [INFO] Results saved successfully.\n"
     ]
    }
   ],
   "source": [
    "with open(\"results.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results, f, indent=4)\n",
    "\n",
    "df = pd.json_normalize(results)\n",
    "df.to_csv(\"results.csv\", index=False)\n",
    "\n",
    "log(\"Results saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf77920",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
